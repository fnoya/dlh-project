{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dominican-renewal",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "entertaining-bottom",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import string\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "latter-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed = 230729\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-provision",
   "metadata": {},
   "source": [
    "We know that not all patients have the same number of visit dates, therefore, we need to find what is the maximum number of visit dates for any given patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fifteen-testament",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "505\n"
     ]
    }
   ],
   "source": [
    "patients_max_visits = 505\n",
    "print(patients_max_visits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-sapphire",
   "metadata": {},
   "source": [
    "In preparation to run the models training on CUDA, we need to make sure that we do have a device and load the tensors and model to CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "advance-documentation",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using device: cuda\n\nNVIDIA GeForce GTX 1060 6GB\nMemory Usage:\nAllocated: 0.0 GB\nCached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-permit",
   "metadata": {},
   "source": [
    "We will need a function to load the pre-processed train and test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "thermal-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Events global variables\n",
    "\"\"\"\n",
    "events_items = pd.DataFrame()\n",
    "events_values = pd.DataFrame()\n",
    "max_code = 0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "purple-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_notes_dataset_object(prefix = ''):\n",
    "    \n",
    "    patient_subject_id = np.load(prefix + 'subject_id.npy', allow_pickle=True).tolist()\n",
    "    patients_notes_fetures = np.load(prefix + 'patients_notes_fetures.npy', allow_pickle=True)\n",
    "    index_0 = np.load(prefix + 'index_0.npy', allow_pickle=True)\n",
    "    index_1 = np.load(prefix + 'index_1.npy', allow_pickle=True)\n",
    "    patients_notes_last_date = np.load(prefix + 'patients_notes_last_date.npy', allow_pickle=True)\n",
    "    patient_mortality = np.load(prefix + 'patient_mortality.npy', allow_pickle=True)\n",
    "    \n",
    "    ### Loading of Events data\n",
    "    events_prefix = \"balanced_test_\" if prefix==\"test_\" else \"balanced_train_\" if prefix==\"train_\" else \"\"\n",
    "    global events_items, events_values, max_code\n",
    "    events_items = pickle.load( open( events_prefix+\"events_item.p\", \"rb\" ) )\n",
    "    events_values = pickle.load(open(events_prefix+\"events_value.p\", \"rb\") )\n",
    "    max_code = pickle.load(open('events_maxcode.p', 'rb')) + 1\n",
    "\n",
    "    assert len(events_items)==len(events_values) and len(events_values['subject_id'].unique()) == len(events_items['subject_id'].unique()) == len(patient_mortality) , \"Wrong events dataframes?\"\n",
    "    assert max_code==127, \"EVENTS MAX CODE changed?\"\n",
    "    ### End Loading of Events data\n",
    "    \n",
    "    return patient_subject_id, patients_notes_fetures, index_0, index_1, patients_notes_last_date, patient_mortality, events_items, events_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-trout",
   "metadata": {},
   "source": [
    "We now load the objects we for train and test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\" Only Run this if you wan to run against original dataset\"\"\"\n",
    "orig_subject_id, orig_patients_notes_fetures, orig_index_0, orig_index_1, orig_patients_notes_last_date, orig_patient_mortality, orig_events_items, orig_events_values = load_notes_dataset_object(prefix = 'orig_')\n",
    "orig_index = [orig_index_0, orig_index_1]\n",
    "orig_patients_notes_fetures = torch.sparse_coo_tensor(orig_index, orig_patients_notes_fetures, (len(orig_subject_id),patients_max_visits,200), dtype = torch.float)\n",
    "orig_patients_notes_last_date = torch.from_numpy(orig_patients_notes_last_date).long()\n",
    "orig_patient_mortality = torch.from_numpy(orig_patient_mortality).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "careful-hotel",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subject_id, train_patients_notes_fetures, train_index_0, train_index_1, train_patients_notes_last_date, train_patient_mortality, train_events_items, train_events_values = load_notes_dataset_object(prefix = 'train_')\n",
    "train_index = [train_index_0, train_index_1]\n",
    "train_patients_notes_fetures = torch.sparse_coo_tensor(train_index, train_patients_notes_fetures, (len(train_subject_id),patients_max_visits,200), dtype = torch.float)\n",
    "train_patients_notes_last_date = torch.from_numpy(train_patients_notes_last_date).long()\n",
    "train_patient_mortality = torch.from_numpy(train_patient_mortality).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subject_id, test_patients_notes_fetures, test_index_0, test_index_1, test_patients_notes_last_date, test_patient_mortality, test_events_items, test_events_values = load_notes_dataset_object(prefix = 'test_')\n",
    "test_index = [test_index_0, test_index_1]\n",
    "test_patients_notes_fetures = torch.sparse_coo_tensor(test_index, test_patients_notes_fetures, (len(test_subject_id),patients_max_visits,200), dtype = torch.float)\n",
    "test_patients_notes_last_date = torch.from_numpy(test_patients_notes_last_date).long()\n",
    "test_patient_mortality = torch.from_numpy(test_patient_mortality).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-employer",
   "metadata": {},
   "source": [
    "Now we are going to create a custom notes dataset to then partition the data in batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "preliminary-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NotesEventsDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, patient_id, patients_notes, last_date_idx, events_items, events_values, mortality):\n",
    "        \n",
    "        self.patient_id = patient_id\n",
    "        len_events_patients = len(events_items['subject_id'].unique())\n",
    "        self.x = patients_notes.to(device, non_blocking=True)\n",
    "        self.mask = last_date_idx.to(device, non_blocking=True)\n",
    "        self.y = mortality.to(device, non_blocking=True)\n",
    "        self.items = events_items.groupby('subject_id').agg('codes').apply(list).values\n",
    "        self.values = events_values.groupby('subject_id').agg('values').apply(list).values\n",
    "        assert len(self.x) == len_events_patients, 'Notes patients and events patients counts do not match!'\n",
    "        r = random.randrange(len(self.x))\n",
    "        assert events_items['subject_id'].unique()[r] == self.patient_id[r], 'Notes and events patient id=' + str(r) + ' does not match'\n",
    "    \n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        events = np.zeros([len(self.items[index]), max_code])\n",
    "\n",
    "        for i, codes in enumerate(self.items[index]):\n",
    "            for j, code in enumerate(codes):\n",
    "                v = self.values[index][i][j]\n",
    "                events[i, code] = v if not math.isnan(v) else 0.0\n",
    "        \n",
    "\n",
    "        return(self.x[index].to_dense(), self.mask[index], events, self.y[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Patients: 9822\nLen of Train dataset: 9822\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Only run this if you wan to run against original dataset\"\"\"\n",
    "orig_dataset = NotesEventsDataset(orig_subject_id, orig_patients_notes_fetures, orig_patients_notes_last_date, orig_events_items, orig_events_values, orig_patient_mortality)\n",
    "print (\"Train Patients:\", len(orig_patient_mortality))\n",
    "print (\"Len of Train dataset:\", len(orig_dataset))\n",
    "assert len(orig_patient_mortality) == len(orig_dataset), 'Wrong dataset length!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hired-plymouth",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Patients: 13790\nLen of Train dataset: 13790\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Run this if you wan to run against balanced dataset\"\"\"\n",
    "train_dataset = NotesEventsDataset(train_subject_id, train_patients_notes_fetures, train_patients_notes_last_date, train_events_items, train_events_values, train_patient_mortality)\n",
    "print (\"Train Patients:\", len(train_patient_mortality))\n",
    "print (\"Len of Train dataset:\", len(train_dataset))\n",
    "assert len(train_patient_mortality) == len(train_dataset), 'Wrong dataset length!'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Patients: 1965\nLen of Test dataset: 1965\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Run this if you wan to run against balanced dataset\"\"\"\n",
    "test_dataset = NotesEventsDataset(test_subject_id, test_patients_notes_fetures, test_patients_notes_last_date, test_events_items, test_events_values, test_patient_mortality)\n",
    "print (\"Test Patients:\", len(test_patient_mortality))\n",
    "print (\"Len of Test dataset:\", len(test_dataset))\n",
    "assert len(test_patient_mortality) == len(test_dataset), 'Wrong dataset length!'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-chart",
   "metadata": {},
   "source": [
    "Now we create the data loaders, splitting the dataset on 80% train, 20% validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "associate-seeking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    x, notes_mask, events, mortality_flag = zip(*data)\n",
    "    \n",
    "    maxvisits = max([len(p) for p in events])\n",
    "    \n",
    "    events_result = torch.tensor([np.concatenate((p, np.zeros([maxvisits - len(p), max_code]))) for p in events]).float()\n",
    "    events_mask = torch.tensor([np.concatenate((np.ones(len(p)), np.zeros(maxvisits - len(p)))) for p in events]).int()\n",
    "    x = torch.stack(x)\n",
    "    notes_mask = torch.stack(notes_mask)\n",
    "    mortality_flag = torch.stack(mortality_flag)\n",
    "    events_result = events_result.to(device, non_blocking=True)\n",
    "    events_mask = events_mask.to(device, non_blocking=True)\n",
    "    return x, notes_mask, events_result, events_mask, mortality_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "floral-attitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Only run this if you want to run against original dataset (not balanced)\"\"\"\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.manual_seed(230729)\n",
    "split = int(len(orig_dataset)*0.8)\n",
    "lengths = [split, len(orig_dataset) - split]\n",
    "\n",
    "orig_train_dataset, orig_val_dataset = random_split(orig_dataset, lengths)\n",
    "train_loader = DataLoader(orig_train_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(orig_val_dataset, batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "expressed-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"Run This if you want to run against Balanced dataset\"\"\"\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 50\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
    "\n",
    "loader_iter = iter(train_loader)\n",
    "x, masks, events, events_masks, y = next(loader_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-carolina",
   "metadata": {},
   "source": [
    "Now We can proceed to create our RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "disabled-chancellor",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotesRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, notes_emb_size=128, input_notes_emb_size=200):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb_size = notes_emb_size\n",
    "        self.RNN = nn.GRU(input_size = input_notes_emb_size, hidden_size = notes_emb_size, batch_first = True)\n",
    "        self.fc1 = nn.Linear(notes_emb_size, notes_emb_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout()\n",
    "        #self.fc2 = nn.Linear(notes_emb_size,128)\n",
    "        #self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, masks, step):\n",
    "                \n",
    "        rnn_out = self.RNN(x)\n",
    "        last_note_date_hs = get_last_note_date(rnn_out[0],masks)\n",
    "        fc1_out = self.fc1(last_note_date_hs)\n",
    "        fc1_out = self.relu(fc1_out)\n",
    "        dp_out = self.dropout(fc1_out)\n",
    "        #fc2_out = self.fc2(dp_out)\n",
    "        #out = self.sig(fc2_out).flatten()\n",
    "\n",
    "        return dp_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-mediterranean",
   "metadata": {},
   "source": [
    "Since the number of date_notes is not the same for each patient, we need to get the hidden state for the last note date for each patient, for that we implement the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sudden-regard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_note_date(hidden_states, masks):   \n",
    "    #last_visit = ((masks.sum(axis = 2) > 0).sum(axis = 1) - 1).unsqueeze(-1)\n",
    "    #if(step == 134):\n",
    "    #print(masks)\n",
    "    #print(hidden_states.shape)\n",
    "    last_visit = masks.expand(-1,hidden_states.shape[2]).unsqueeze(1)\n",
    "    \n",
    "    out = torch.gather(hidden_states,dim = 1,index = last_visit)[:,-1,:]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "decent-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_output_volume(W, K, S, P):\n",
    "    \n",
    "\n",
    "    \n",
    "    return  (((W-K+2*P)//S)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-intro",
   "metadata": {},
   "source": [
    "## Events Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "funky-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventsRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_codes=max_code, emb_size=128):\n",
    "        super().__init__()\n",
    "        \n",
    "       # self.embedding = nn.Embedding(num_codes, emb_size)\n",
    "        self.rnn = nn.GRU(num_codes, hidden_size=emb_size, batch_first=True)\n",
    "        #self.fc1 = nn.Linear(emb_size, 128)\n",
    "        #self.sig = nn.Sigmoid()\n",
    "\n",
    "    \n",
    "    def forward(self, events, masks):\n",
    "        \n",
    "        rnn_hidden_states, _ = self.rnn(events)        \n",
    "        real_hidden_states = rnn_hidden_states * masks.unsqueeze(-1).expand(rnn_hidden_states.shape)\n",
    "        sum_hidden_states = real_hidden_states.sum(dim=1)\n",
    "        \n",
    "        #fc1 = self.fc1(sum_hidden_states)\n",
    "        #output = self.sig(fc1).flatten()\n",
    "        return sum_hidden_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-castle",
   "metadata": {},
   "source": [
    "## Final Classifier Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "brief-campus",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OutNet(\n",
       "  (notes): NotesRNN(\n",
       "    (RNN): GRU(200, 128, batch_first=True)\n",
       "    (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (events): EventsRNN(\n",
       "    (rnn): GRU(127, 128, batch_first=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "class OutNet(nn.Module):\n",
    "    def __init__(self, notes_embeddings=128, events_embeddings=128):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.notes = NotesRNN(notes_embeddings)\n",
    "        self.events = EventsRNN(emb_size=events_embeddings)\n",
    "        if torch.cuda.device_count() >0:\n",
    "            self.notes.cuda()\n",
    "            self.events.cuda()\n",
    "        self.fc1 = nn.Linear(notes_embeddings + events_embeddings, 128)\n",
    "        self.fc2 = nn.Linear(128, 32)\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.sig = nn.Sigmoid()    \n",
    "    \n",
    "    def forward(self, x, masks, events, events_masks, step):\n",
    "        \n",
    "        notes_emb = self.notes(x, masks, step)\n",
    "        events_emb = self.events(events, events_masks)\n",
    "        \n",
    "        joint_emb = torch.cat([notes_emb, events_emb], dim=1)\n",
    "        \n",
    "        fc1 = self.fc1(joint_emb)\n",
    "        fc2 = self.dropout(self.fc2(fc1))\n",
    "        fc3 = self.fc3(fc2)\n",
    "        output = self.sig(fc3).flatten()\n",
    "        return output\n",
    "\n",
    "outNet = OutNet()\n",
    "outNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "electoral-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, n_epochs):\n",
    "    model.train() # prep model for training\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        curr_epoch_loss = []\n",
    "        print('Batch :', end = ' ')\n",
    "        for step, batch in enumerate(train_loader):\n",
    "            if step % 10 == 0 and step>0:\n",
    "                print(str(step)+',', end=' ' )\n",
    "                #print(f\"Epoch {epoch}: curr_epoch_loss={np.mean(curr_epoch_loss)}\")\n",
    "            x, masks, events, events_masks, labels = batch\n",
    "            #print('Events is cuda:' + str(events.is_cuda))\n",
    "        \n",
    "            \"\"\" Step 1. clear gradients \"\"\"\n",
    "            optimizer.zero_grad()\n",
    "            \"\"\" Step 2. evaluate model ouput  \"\"\"\n",
    "            probs = model(x, masks, events, events_masks, step)\n",
    "            \"\"\" Step 3. Calculate loss  \"\"\"\n",
    "            loss = criterion(probs, labels)\n",
    "            \"\"\" Step 4. Backward propagation  \"\"\"\n",
    "            loss.backward()\n",
    "            \"\"\" Step 5. optimization \"\"\"\n",
    "            optimizer.step()\n",
    "            \"\"\" Step 6. record loss \"\"\"\n",
    "            curr_epoch_loss.append(loss.cpu().data.numpy())\n",
    "        \n",
    "        \n",
    "        print(f\"Epoch {epoch}: curr_epoch_loss={np.mean(curr_epoch_loss)}\")\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "metric-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "\n",
    "def eval_model(model, val_loader):\n",
    "    model.eval()\n",
    "    val_labels = []\n",
    "    val_probs = []\n",
    "    \n",
    "    for step, batch in enumerate(val_loader):\n",
    "        x, masks, events, events_masks, labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            probs = model(x, masks, events, events_masks, 0)\n",
    "            val_labels.extend(labels.detach().cpu().numpy().tolist())\n",
    "            val_probs.extend(probs.detach().cpu().numpy().reshape(-1).tolist())\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(val_labels, np.array(val_probs)>0.5, average='binary')\n",
    "    roc_auc = roc_auc_score(val_labels, val_probs)\n",
    "    \n",
    "    return precision, recall, f1, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "liable-scholar",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "model = OutNet(notes_embeddings=128, events_embeddings=128)\n",
    "if torch.cuda.device_count() >0:\n",
    "    model.cuda()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum = 0.9, nesterov = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "rotary-compensation",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Learning Rate: 0.001\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 0: curr_epoch_loss=0.9669583439826965\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 1: curr_epoch_loss=0.5856062769889832\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 2: curr_epoch_loss=0.40844157338142395\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 3: curr_epoch_loss=0.3442745804786682\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 4: curr_epoch_loss=0.3008953928947449\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 5: curr_epoch_loss=0.30304819345474243\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 6: curr_epoch_loss=0.28896281123161316\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 7: curr_epoch_loss=0.2911911904811859\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 8: curr_epoch_loss=0.2715715765953064\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 9: curr_epoch_loss=0.28077536821365356\n",
      "Model Training time: 349.11223673820496\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "t0 = time.time()\n",
    "print('Learning Rate: ' + str(learning_rate))\n",
    "n_epochs = 10\n",
    "train(model, train_loader, n_epochs)\n",
    "t1 = time.time()\n",
    "processing_time = t1-t0\n",
    "print('Model Training time: ' + str(processing_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "brutal-chicago",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Learning rate: 0.001\nModel Training time: 349.11223673820496\nPrecision =  0.624\nRecall    =  0.3627906976744186\nF1        =  0.45882352941176474\nROC AUC   =  0.8613222591362126\n"
     ]
    }
   ],
   "source": [
    "p, r, f, roc_auc = eval_model(model, val_loader)\n",
    "print (\"Learning rate: \" + str(learning_rate))\n",
    "print(\"Model Training time: \" + str(processing_time))\n",
    "print(\"Precision = \",p)\n",
    "print(\"Recall    = \", r)\n",
    "print(\"F1        = \", f)\n",
    "print(\"ROC AUC   = \", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-castle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd0b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f",
   "display_name": "Python 3.8.5 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}