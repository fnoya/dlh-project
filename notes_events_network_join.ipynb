{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "million-august",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "early-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import string\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-makeup",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "resistant-water",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "seed = 230729\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "max_code = pickle.load(open('events_maxcode.p', 'rb')) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-crawford",
   "metadata": {},
   "source": [
    "We know that not all patients have the same number of visit dates, therefore, we need to find what is the maximum number of visit dates for any given patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "owned-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_max_visits = 505"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-reader",
   "metadata": {},
   "source": [
    "In preparation to run the models training on CUDA, we need to make sure that we do have a device and load the tensors and model to CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "generous-crest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-witness",
   "metadata": {},
   "source": [
    "## Loading data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "viral-nurse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_events_dataset_object(prefix=''):\n",
    "    return pickle.load( open(prefix + \"events_item.p\", \"rb\" )), pickle.load(open(prefix + \"events_value.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "copyrighted-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_notes_dataset_object(prefix = ''):\n",
    "    \n",
    "    patient_subject_id = np.load(prefix + 'subject_id.npy', allow_pickle=True).tolist()\n",
    "    patients_notes_fetures = np.load(prefix + 'patients_notes_fetures.npy', allow_pickle=True)\n",
    "    index_0 = np.load(prefix + 'index_0.npy', allow_pickle=True)\n",
    "    index_1 = np.load(prefix + 'index_1.npy', allow_pickle=True)\n",
    "    patients_notes_last_date = np.load(prefix + 'patients_notes_last_date.npy', allow_pickle=True)\n",
    "    patient_mortality = np.load(prefix + 'patient_mortality.npy', allow_pickle=True)\n",
    "\n",
    "    return patient_subject_id, patients_notes_fetures, index_0, index_1, patients_notes_last_date, patient_mortality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-mandate",
   "metadata": {},
   "source": [
    "## Dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lined-greece",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotesEventsDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, patient_id, patients_notes, last_date_idx, events_items, events_values, mortality):\n",
    "        \n",
    "        self.patient_id = patient_id\n",
    "        len_events_patients = len(events_items['subject_id'].unique())\n",
    "        self.x = patients_notes.to(device, non_blocking=True)\n",
    "        self.mask = last_date_idx.to(device, non_blocking=True)\n",
    "        self.y = mortality.to(device, non_blocking=True)\n",
    "        self.items = events_items.groupby('subject_id').agg('codes').apply(list).values\n",
    "        self.values = events_values.groupby('subject_id').agg('values').apply(list).values\n",
    "        assert len(self.x) == len_events_patients, 'Notes patients and events patients counts do not match!'\n",
    "        r = random.randrange(len(self.x))\n",
    "        assert events_items['subject_id'].unique()[r] == self.patient_id[r], 'Notes and events patient id=' + str(r) + ' does not match'\n",
    "    \n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        events = np.zeros([len(self.items[index]), max_code])\n",
    "\n",
    "        for i, codes in enumerate(self.items[index]):\n",
    "            for j, code in enumerate(codes):\n",
    "                v = self.values[index][i][j]\n",
    "                events[i, code] = v if not math.isnan(v) else 0.0\n",
    "        \n",
    "\n",
    "        return(self.x[index].to_dense(), self.mask[index], events, self.y[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "noted-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset (cohort_type = 'original'):\n",
    "    \"\"\"\n",
    "    cohort_type = 'original' -> Unbalanced cohort will be created\n",
    "    cohort_type = 'balanced_train' -> Balanced cohort for training will be created\n",
    "    cohort_type = 'balanced_test' -> Balanced cohort for testing will be created\n",
    "    \"\"\"\n",
    "    notes_prefix = \"orig_\" if cohort_type == 'original' else \"train_\" if cohort_type == 'balanced_train' else \"test_\"\n",
    "    subject_id, patients_notes_fetures, index_0, index_1, patients_notes_last_date, patient_mortality= load_notes_dataset_object(prefix = notes_prefix)\n",
    "    index = [index_0, index_1]\n",
    "    patients_notes_fetures = torch.sparse_coo_tensor(index, patients_notes_fetures, (len(subject_id),patients_max_visits,200), dtype = torch.float)\n",
    "    patients_notes_last_date = torch.from_numpy(patients_notes_last_date).long()\n",
    "    patient_mortality = torch.from_numpy(patient_mortality).float()    \n",
    "    \n",
    "    events_prefix = \"\" if cohort_type=='original' else cohort_type +\"_\" \n",
    "    events_items, events_values = load_events_dataset_object(events_prefix)\n",
    "\n",
    "    assert len(events_items)==len(events_values) and len(events_values['subject_id'].unique()) == len(events_items['subject_id'].unique()) == len(patient_mortality) , \"Wrong events dataframes?\"\n",
    "    assert max_code==127, \"EVENTS MAX CODE changed?\"\n",
    "\n",
    "    dataset = NotesEventsDataset(subject_id, patients_notes_fetures, patients_notes_last_date, events_items, events_values, patient_mortality)\n",
    "    assert len(patient_mortality) == len(dataset), 'Wrong dataset length!'\n",
    "    print (\"Number of Patients:\", len(patient_mortality))\n",
    "\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-village",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "directed-layout",
   "metadata": {},
   "source": [
    "## DataLoader definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-patio",
   "metadata": {},
   "source": [
    "### Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "synthetic-reynolds",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "exact-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    x, notes_mask, events, mortality_flag = zip(*data)\n",
    "    \n",
    "    maxvisits = max([len(p) for p in events])\n",
    "    \n",
    "    events_result = torch.tensor([np.concatenate((p, np.zeros([maxvisits - len(p), max_code]))) for p in events]).float()\n",
    "    events_mask = torch.tensor([np.concatenate((np.ones(len(p)), np.zeros(maxvisits - len(p)))) for p in events]).int()\n",
    "    x = torch.stack(x)\n",
    "    notes_mask = torch.stack(notes_mask)\n",
    "    mortality_flag = torch.stack(mortality_flag)\n",
    "    events_result = events_result.to(device, non_blocking=True)\n",
    "    events_mask = events_mask.to(device, non_blocking=True)\n",
    "    return x, notes_mask, events_result, events_mask, mortality_flag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-surgeon",
   "metadata": {},
   "source": [
    "Now we create the data loaders, splitting the dataset on 80% train, 20% validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "compliant-publisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unbalanced_dataloaders (max_size = 0):\n",
    "\n",
    "    dataset = create_dataset('original')\n",
    "    if (max_size > 0):\n",
    "        print (\"***** Slicing to \" + str(max_size))\n",
    "        dataset = Subset(dataset, np.arange(max_size))\n",
    "\n",
    "    split = int(len(dataset)*0.8)\n",
    "    lengths = [split, len(dataset) - split]\n",
    "\n",
    "    train_dataset, val_dataset = random_split(dataset, lengths)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "affected-matter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_balanced_dataloaders (max_size = 0):\n",
    "\n",
    "    print (\"* Train dataset *\")\n",
    "    balanced_train_dataset = create_dataset('balanced_train')\n",
    "    print (\"* Test dataset *\")\n",
    "    balanced_test_dataset = create_dataset('balanced_test')\n",
    "\n",
    "    if (max_size > 0):\n",
    "        print (\"***** Slicing to \" + str(max_size))\n",
    "        balanced_train_dataset = Subset(balanced_train_dataset, np.arange(max_size))\n",
    "        balanced_test_dataset = Subset(balanced_test_dataset, np.arange(max_size))\n",
    "\n",
    "    train_loader = DataLoader(balanced_train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "    val_loader = DataLoader(balanced_test_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-remedy",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-pharmacy",
   "metadata": {},
   "source": [
    "## Notes Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "domestic-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotesRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, notes_emb_size=128, input_notes_emb_size=200):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb_size = notes_emb_size\n",
    "        self.RNN = nn.GRU(input_size = input_notes_emb_size, hidden_size = notes_emb_size, batch_first = True)\n",
    "        self.fc1 = nn.Linear(notes_emb_size, notes_emb_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout()\n",
    "        #self.fc2 = nn.Linear(notes_emb_size,128)\n",
    "        #self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, masks, step):\n",
    "                \n",
    "        rnn_out = self.RNN(x)\n",
    "        last_note_date_hs = get_last_note_date(rnn_out[0],masks)\n",
    "        fc1_out = self.fc1(last_note_date_hs)\n",
    "        fc1_out = self.relu(fc1_out)\n",
    "        dp_out = self.dropout(fc1_out)\n",
    "        #fc2_out = self.fc2(dp_out)\n",
    "        #out = self.sig(fc2_out).flatten()\n",
    "\n",
    "        return dp_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-stranger",
   "metadata": {},
   "source": [
    "Since the number of date_notes is not the same for each patient, we need to get the hidden state for the last note date for each patient, for that we implement the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "presidential-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_note_date(hidden_states, masks):   \n",
    "    #last_visit = ((masks.sum(axis = 2) > 0).sum(axis = 1) - 1).unsqueeze(-1)\n",
    "    #if(step == 134):\n",
    "    #print(masks)\n",
    "    #print(hidden_states.shape)\n",
    "    last_visit = masks.expand(-1,hidden_states.shape[2]).unsqueeze(1)\n",
    "    \n",
    "    out = torch.gather(hidden_states,dim = 1,index = last_visit)[:,-1,:]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "institutional-confirmation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_output_volume(W, K, S, P):    \n",
    "    return  (((W-K+2*P)//S)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-newman",
   "metadata": {},
   "source": [
    "## Events Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "photographic-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventsRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_codes=max_code, emb_size=128):\n",
    "        super().__init__()\n",
    "        \n",
    "       # self.embedding = nn.Embedding(num_codes, emb_size)\n",
    "        self.rnn = nn.GRU(num_codes, hidden_size=emb_size, batch_first=True)\n",
    "        #self.fc1 = nn.Linear(emb_size, 128)\n",
    "        #self.sig = nn.Sigmoid()\n",
    "\n",
    "    \n",
    "    def forward(self, events, masks):\n",
    "        \n",
    "        rnn_hidden_states, _ = self.rnn(events)        \n",
    "        real_hidden_states = rnn_hidden_states * masks.unsqueeze(-1).expand(rnn_hidden_states.shape)\n",
    "        sum_hidden_states = real_hidden_states.sum(dim=1)\n",
    "        \n",
    "        #fc1 = self.fc1(sum_hidden_states)\n",
    "        #output = self.sig(fc1).flatten()\n",
    "        return sum_hidden_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-titanium",
   "metadata": {},
   "source": [
    "## Final Classifier Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "needed-armenia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutNet(\n",
       "  (notes): NotesRNN(\n",
       "    (RNN): GRU(200, 128, batch_first=True)\n",
       "    (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (events): EventsRNN(\n",
       "    (rnn): GRU(127, 128, batch_first=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class OutNet(nn.Module):\n",
    "    def __init__(self, notes_embeddings=128, events_embeddings=128):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.notes = NotesRNN(notes_embeddings)\n",
    "        self.events = EventsRNN(emb_size=events_embeddings)\n",
    "        if torch.cuda.device_count() >0:\n",
    "            self.notes.cuda()\n",
    "            self.events.cuda()\n",
    "        self.fc1 = nn.Linear(notes_embeddings + events_embeddings, 128)\n",
    "        self.fc2 = nn.Linear(128, 32)\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.sig = nn.Sigmoid()    \n",
    "    \n",
    "    def forward(self, x, masks, events, events_masks, step):\n",
    "        \n",
    "        notes_emb = self.notes(x, masks, step)\n",
    "        events_emb = self.events(events, events_masks)\n",
    "        \n",
    "        joint_emb = torch.cat([notes_emb, events_emb], dim=1)\n",
    "        \n",
    "        fc1 = self.fc1(joint_emb)\n",
    "        fc2 = self.dropout(self.fc2(fc1))\n",
    "        fc3 = self.fc3(fc2)\n",
    "        output = self.sig(fc3).flatten()\n",
    "        return output\n",
    "\n",
    "outNet = OutNet()\n",
    "outNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "advance-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_and_optimizer():\n",
    "    model = OutNet(notes_embeddings=128, events_embeddings=128)\n",
    "    if torch.cuda.device_count() >0:\n",
    "        model.cuda()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum = 0.9, nesterov = True)\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-story",
   "metadata": {},
   "source": [
    "# Model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "diagnostic-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, n_epochs):\n",
    "    model.train() # prep model for training\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        curr_epoch_loss = []\n",
    "        print('Batch :', end = ' ')\n",
    "        for step, batch in enumerate(train_loader):\n",
    "            if step % 10 == 0 and step>0:\n",
    "                print(str(step)+',', end=' ' )\n",
    "            x, masks, events, events_masks, labels = batch\n",
    "        \n",
    "            \"\"\" Step 1. clear gradients \"\"\"\n",
    "            optimizer.zero_grad()\n",
    "            \"\"\" Step 2. evaluate model ouput  \"\"\"\n",
    "            probs = model(x, masks, events, events_masks, step)\n",
    "            \"\"\" Step 3. Calculate loss  \"\"\"\n",
    "            loss = criterion(probs, labels)\n",
    "            \"\"\" Step 4. Backward propagation  \"\"\"\n",
    "            loss.backward()\n",
    "            \"\"\" Step 5. optimization \"\"\"\n",
    "            optimizer.step()\n",
    "            \"\"\" Step 6. record loss \"\"\"\n",
    "            curr_epoch_loss.append(loss.cpu().data.numpy())\n",
    "        \n",
    "        \n",
    "        print(f\"Epoch {epoch}: curr_epoch_loss={np.mean(curr_epoch_loss)}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "combined-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, val_loader):\n",
    "    model.eval()\n",
    "    val_labels = []\n",
    "    val_probs = []\n",
    "    \n",
    "    for step, batch in enumerate(val_loader):\n",
    "        x, masks, events, events_masks, labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            probs = model(x, masks, events, events_masks, 0)\n",
    "            val_labels.extend(labels.detach().cpu().numpy().tolist())\n",
    "            val_probs.extend(probs.detach().cpu().numpy().reshape(-1).tolist())\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(val_labels, np.array(val_probs)>0.5, average='binary')\n",
    "    roc_auc = roc_auc_score(val_labels, val_probs)\n",
    "    \n",
    "    return precision, recall, f1, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "stable-arthur",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(model, train_loader, val_loader, n_epochs=10, filename='model.pt'):\n",
    "    t0 = time.time()\n",
    "    train(model, train_loader, n_epochs)\n",
    "    t1 = time.time()\n",
    "    processing_time = t1-t0\n",
    "    print('Model Training time: ' + str(processing_time))\n",
    "    \n",
    "    p, r, f, roc_auc = eval_model(model, val_loader)\n",
    "    print (\"Learning rate: \" + str(learning_rate))\n",
    "    print(\"Model Training time: \" + str(processing_time))\n",
    "    print(\"Precision = \",p)\n",
    "    print(\"Recall    = \", r)\n",
    "    print(\"F1        = \", f)\n",
    "    print(\"ROC AUC   = \", roc_auc)\n",
    "    \n",
    "    if filename is not None:\n",
    "        torch.save(model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "limited-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_eval(model, modelfilename, val_loader):  \n",
    "    print (\"**LOADING MODEL** from \" + modelfilename)\n",
    "    model.load_state_dict(torch.load(modelfilename))\n",
    "    p, r, f, roc_auc = eval_model(model, val_loader)\n",
    "    print (\"\")\n",
    "    print(\"Precision = \",p)\n",
    "    print(\"Recall    = \", r)\n",
    "    print(\"F1        = \", f)\n",
    "    print(\"ROC AUC   = \", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-diving",
   "metadata": {},
   "source": [
    "# Main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-indicator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 0.001\n",
      "Number of Epochs: 10\n",
      "\n",
      "--------------\n",
      "Original model\n",
      "--------------\n",
      "Number of Patients: 9822\n",
      "**LOADING MODEL** from unbalanced_model.pt\n",
      "\n",
      "Precision =  0.6940298507462687\n",
      "Recall    =  0.41333333333333333\n",
      "F1        =  0.5181058495821727\n",
      "ROC AUC   =  0.8978033205619412\n",
      "\n",
      "\n",
      "--------------\n",
      "Balanced model\n",
      "--------------\n",
      "* Train dataset *\n",
      "Number of Patients: 13790\n",
      "* Test dataset *\n",
      "Number of Patients: 1965\n",
      "Batch : 10, "
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "n_epochs = 10\n",
    "criterion = nn.BCELoss()\n",
    "print('Learning Rate: ' + str(learning_rate))\n",
    "print (\"Number of Epochs: \" + str(n_epochs))\n",
    "\n",
    "print ('')\n",
    "print ('--------------')\n",
    "print ('Original model')\n",
    "print ('--------------')\n",
    "model, optimizer = create_model_and_optimizer()\n",
    "train_loader, val_loader = get_unbalanced_dataloaders()   # You can pass a number to limit the number of samples\n",
    "\n",
    "#train_and_eval(model, train_loader, val_loader, n_epochs, 'unbalanced_model.pt')\n",
    "load_and_eval(model, 'unbalanced_model.pt', val_loader)\n",
    "\n",
    "print ('')\n",
    "print ('')\n",
    "print ('--------------')\n",
    "print ('Balanced model')\n",
    "print ('--------------')\n",
    "model, optimizer = create_model_and_optimizer()\n",
    "train_loader, val_loader = get_balanced_dataloaders()       # You can pass a number to limit the number of samples\n",
    "train_and_eval(model, train_loader, val_loader, n_epochs, 'balanced_model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-processing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "metadata": {
   "interpreter": {
    "hash": "372d86228f3adce91ee8f73488429c59d9cef194793ee1ea2efae707e6a5484f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
