{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "norwegian-affairs",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "peripheral-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import string\n",
    "# import nltk\n",
    "#from nltk import word_tokenize\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "#import boto3\n",
    "#from botocore.client import ClientError\n",
    "# below is used to print out pretty pandas dataframes\n",
    "#from IPython.display import display, HTML\n",
    "\n",
    "#from pyathena import connect\n",
    "#from pyathena.pandas.util import as_pandas\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "import math\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alpine-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed = 230729\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "PATIENTS = 0  # 0 - ALL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-indiana",
   "metadata": {},
   "source": [
    "We know that not all patients have the same number of visit dates, therefore, we need to find what is the maximum number of visit dates for any given patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accompanied-better",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505\n"
     ]
    }
   ],
   "source": [
    "patients_max_visits = 505\n",
    "print(patients_max_visits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-region",
   "metadata": {},
   "source": [
    "In preparation to run the models training on CUDA, we need to make sure that we do have a device and load the tensors and model to CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "approved-ethernet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n\nNVIDIA GeForce GTX 1060 6GB\nMemory Usage:\nAllocated: 0.0 GB\nCached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-insider",
   "metadata": {},
   "source": [
    "We will need a function to load the pre-processed train and test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "precious-classroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_notes_dataset_object(prefix = ''):\n",
    "    \n",
    "    patient_subject_id = np.load(prefix + 'subject_id.npy', allow_pickle=True).tolist()\n",
    "    patients_notes_fetures = np.load(prefix + 'patients_notes_fetures.npy', allow_pickle=True)\n",
    "    index_0 = np.load(prefix + 'index_0.npy', allow_pickle=True)\n",
    "    index_1 = np.load(prefix + 'index_1.npy', allow_pickle=True)\n",
    "    patients_notes_last_date = np.load(prefix + 'patients_notes_last_date.npy', allow_pickle=True)\n",
    "    patient_mortality = np.load(prefix + 'patient_mortality.npy', allow_pickle=True)\n",
    "    \n",
    "    return patient_subject_id, patients_notes_fetures, index_0, index_1, patients_notes_last_date, patient_mortality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-large",
   "metadata": {},
   "source": [
    "We now load the objects we for train and test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hired-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_items = pickle.load( open( \"events_item.p\", \"rb\" ) )\n",
    "events_values = pickle.load(open(\"events_value.p\", \"rb\") )\n",
    "patients = pickle.load(open('patients.p', 'rb'))\n",
    "max_code = pickle.load(open('events_maxcode.p', 'rb')) + 1\n",
    "\n",
    "assert len(events_items)==174288 and len(events_values)==174288 and len(events_values['subject_id'].unique()) == len(events_items['subject_id'].unique()) == len(patients) == 9822, \"Wrong events dataframes?\"\n",
    "assert max_code==127, \"EVENTS MAX CODE changed?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "biological-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_subject_id, orig_patients_notes_fetures, orig_index_0, orig_index_1, orig_patients_notes_last_date, orig_patient_mortality = load_notes_dataset_object(prefix = 'orig_')\n",
    "orig_index = [orig_index_0, orig_index_1]\n",
    "orig_patients_notes_fetures = torch.sparse_coo_tensor(orig_index, orig_patients_notes_fetures, (len(orig_subject_id),patients_max_visits,200), dtype = torch.float)\n",
    "orig_patients_notes_last_date = torch.from_numpy(orig_patients_notes_last_date).long()\n",
    "orig_patient_mortality = torch.from_numpy(orig_patient_mortality).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-caution",
   "metadata": {},
   "source": [
    "Now we are going to create a custom notes dataset to then partition the data in batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cooperative-steering",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NotesEventsDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, patient_id, patients_notes, last_date_idx, events_items, events_values, mortality):\n",
    "        \n",
    "        self.patient_id = patient_id\n",
    "        len_events_patients = len(events_items['subject_id'].unique())\n",
    "        self.x = patients_notes.to(device, non_blocking=True)\n",
    "        self.mask = last_date_idx.to(device, non_blocking=True)\n",
    "        self.y = mortality.to(device, non_blocking=True)\n",
    "        self.items = events_items.groupby('subject_id').agg('codes').apply(list).values\n",
    "        self.values = events_values.groupby('subject_id').agg('values').apply(list).values\n",
    "        assert len(self.x) == len_events_patients, 'Notes patients and events patients counts do not match!'\n",
    "        r = random.randrange(len(self.x))\n",
    "        assert events_items['subject_id'].unique()[r] == self.patient_id[r], 'Notes and events patient id=' + str(r) + ' does not match'\n",
    "    \n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        events = np.zeros([len(self.items[index]), max_code])\n",
    "\n",
    "        for i, codes in enumerate(self.items[index]):\n",
    "            for j, code in enumerate(codes):\n",
    "                v = self.values[index][i][j]\n",
    "                events[i, code] = v if not math.isnan(v) else 0.0\n",
    "        \n",
    "\n",
    "        return(self.x[index].to_dense(), self.mask[index], events, self.y[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "likely-present",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients: 9822\nLen of dataset: 9822\n"
     ]
    }
   ],
   "source": [
    "notes_orig_dataset = NotesEventsDataset(orig_subject_id, orig_patients_notes_fetures, orig_patients_notes_last_date, events_items, events_values, orig_patient_mortality)\n",
    "print (\"Patients:\", len(patients))\n",
    "print (\"Len of dataset:\", len(notes_orig_dataset))\n",
    "assert len(patients) == len(notes_orig_dataset), 'Wrong dataset length!'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-cylinder",
   "metadata": {},
   "source": [
    "Now we create the data loaders, splitting the dataset on 80% train, 20% validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "warming-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    x, notes_mask, events, mortality_flag = zip(*data)\n",
    "    \n",
    "    maxvisits = max([len(p) for p in events])\n",
    "    \n",
    "    events_result = torch.tensor([np.concatenate((p, np.zeros([maxvisits - len(p), max_code]))) for p in events]).float()\n",
    "    events_mask = torch.tensor([np.concatenate((np.ones(len(p)), np.zeros(maxvisits - len(p)))) for p in events]).int()\n",
    "    x = torch.stack(x)\n",
    "    notes_mask = torch.stack(notes_mask)\n",
    "    mortality_flag = torch.stack(mortality_flag)\n",
    "    events_result = events_result.to(device, non_blocking=True)\n",
    "    events_mask = events_mask.to(device, non_blocking=True)\n",
    "    return x, notes_mask, events_result, events_mask, mortality_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "talented-steering",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "torch.manual_seed(230729)\n",
    "split = int(len(notes_orig_dataset)*0.8)\n",
    "lengths = [split, len(notes_orig_dataset) - split]\n",
    "\n",
    "notes_orig_train_dataset, notes_orig_val_dataset = random_split(notes_orig_dataset, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "residential-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 50\n",
    "notes_orig_train_loader = DataLoader(notes_orig_train_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
    "notes_orig_val_loader = DataLoader(notes_orig_val_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
    "\n",
    "loader_iter = iter(notes_orig_train_loader)\n",
    "x, masks, events, events_masks, y = next(loader_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-passing",
   "metadata": {},
   "source": [
    "Now We can proceed to create our RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dietary-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotesRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, notes_emb_size=128, input_notes_emb_size=200):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb_size = notes_emb_size\n",
    "        self.RNN = nn.GRU(input_size = input_notes_emb_size, hidden_size = notes_emb_size, batch_first = True)\n",
    "        self.fc1 = nn.Linear(notes_emb_size, notes_emb_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout()\n",
    "        #self.fc2 = nn.Linear(notes_emb_size,128)\n",
    "        #self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, masks, step):\n",
    "                \n",
    "        rnn_out = self.RNN(x)\n",
    "        last_note_date_hs = get_last_note_date(rnn_out[0],masks)\n",
    "        fc1_out = self.fc1(last_note_date_hs)\n",
    "        fc1_out = self.relu(fc1_out)\n",
    "        dp_out = self.dropout(fc1_out)\n",
    "        #fc2_out = self.fc2(dp_out)\n",
    "        #out = self.sig(fc2_out).flatten()\n",
    "\n",
    "        return dp_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-three",
   "metadata": {},
   "source": [
    "Since the number of date_notes is not the same for each patient, we need to get the hidden state for the last note date for each patient, for that we implement the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "drawn-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_note_date(hidden_states, masks):   \n",
    "    #last_visit = ((masks.sum(axis = 2) > 0).sum(axis = 1) - 1).unsqueeze(-1)\n",
    "    #if(step == 134):\n",
    "    #print(masks)\n",
    "    #print(hidden_states.shape)\n",
    "    last_visit = masks.expand(-1,hidden_states.shape[2]).unsqueeze(1)\n",
    "    \n",
    "    out = torch.gather(hidden_states,dim = 1,index = last_visit)[:,-1,:]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "monetary-child",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_output_volume(W, K, S, P):\n",
    "    \n",
    "\n",
    "    \n",
    "    return  (((W-K+2*P)//S)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-immune",
   "metadata": {},
   "source": [
    "## Events Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cardiac-blocking",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventsRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_codes=max_code, emb_size=128):\n",
    "        super().__init__()\n",
    "        \n",
    "       # self.embedding = nn.Embedding(num_codes, emb_size)\n",
    "        self.rnn = nn.GRU(num_codes, hidden_size=emb_size, batch_first=True)\n",
    "        #self.fc1 = nn.Linear(emb_size, 128)\n",
    "        #self.sig = nn.Sigmoid()\n",
    "\n",
    "    \n",
    "    def forward(self, events, masks):\n",
    "        \n",
    "        rnn_hidden_states, _ = self.rnn(events)        \n",
    "        real_hidden_states = rnn_hidden_states * masks.unsqueeze(-1).expand(rnn_hidden_states.shape)\n",
    "        sum_hidden_states = real_hidden_states.sum(dim=1)\n",
    "        \n",
    "        #fc1 = self.fc1(sum_hidden_states)\n",
    "        #output = self.sig(fc1).flatten()\n",
    "        return sum_hidden_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-robin",
   "metadata": {},
   "source": [
    "## Final Classifier Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "arranged-definition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutNet(\n",
       "  (notes): NotesRNN(\n",
       "    (RNN): GRU(200, 128, batch_first=True)\n",
       "    (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (events): EventsRNN(\n",
       "    (rnn): GRU(127, 128, batch_first=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class OutNet(nn.Module):\n",
    "    def __init__(self, notes_embeddings=128, events_embeddings=128):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.notes = NotesRNN(notes_embeddings)\n",
    "        self.events = EventsRNN(emb_size=events_embeddings)\n",
    "        if torch.cuda.device_count() >0:\n",
    "            self.notes.cuda()\n",
    "            self.events.cuda()\n",
    "        self.fc1 = nn.Linear(notes_embeddings + events_embeddings, 128)\n",
    "        self.fc2 = nn.Linear(128, 32)\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.sig = nn.Sigmoid()    \n",
    "    \n",
    "    def forward(self, x, masks, events, events_masks, step):\n",
    "        \n",
    "        notes_emb = self.notes(x, masks, step)\n",
    "        events_emb = self.events(events, events_masks)\n",
    "        \n",
    "        joint_emb = torch.cat([notes_emb, events_emb], dim=1)\n",
    "        \n",
    "        fc1 = self.fc1(joint_emb)\n",
    "        fc2 = self.dropout(self.fc2(fc1))\n",
    "        fc3 = self.fc3(fc2)\n",
    "        output = self.sig(fc3).flatten()\n",
    "        return output\n",
    "\n",
    "outNet = OutNet()\n",
    "outNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "massive-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, n_epochs):\n",
    "    model.train() # prep model for training\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        curr_epoch_loss = []\n",
    "        print('Batch :', end = ' ')\n",
    "        for step, batch in enumerate(train_loader):\n",
    "            if step % 10 == 0 and step>0:\n",
    "                print(str(step)+',', end=' ' )\n",
    "                #print(f\"Epoch {epoch}: curr_epoch_loss={np.mean(curr_epoch_loss)}\")\n",
    "            x, masks, events, events_masks, labels = batch\n",
    "            #print('Events is cuda:' + str(events.is_cuda))\n",
    "        \n",
    "            \"\"\" Step 1. clear gradients \"\"\"\n",
    "            optimizer.zero_grad()\n",
    "            \"\"\" Step 2. evaluate model ouput  \"\"\"\n",
    "            probs = model(x, masks, events, events_masks, step)\n",
    "            \"\"\" Step 3. Calculate loss  \"\"\"\n",
    "            loss = criterion(probs, labels)\n",
    "            \"\"\" Step 4. Backward propagation  \"\"\"\n",
    "            loss.backward()\n",
    "            \"\"\" Step 5. optimization \"\"\"\n",
    "            optimizer.step()\n",
    "            \"\"\" Step 6. record loss \"\"\"\n",
    "            curr_epoch_loss.append(loss.cpu().data.numpy())\n",
    "        \n",
    "        \n",
    "        print(f\"Epoch {epoch}: curr_epoch_loss={np.mean(curr_epoch_loss)}\")\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "serial-aquarium",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "\n",
    "def eval_model(model, val_loader):\n",
    "    model.eval()\n",
    "    val_labels = []\n",
    "    val_probs = []\n",
    "    \n",
    "    for step, batch in enumerate(val_loader):\n",
    "        x, masks, events, events_masks, labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            probs = model(x, masks, events, events_masks, 0)\n",
    "            val_labels.extend(labels.detach().cpu().numpy().tolist())\n",
    "            val_probs.extend(probs.detach().cpu().numpy().reshape(-1).tolist())\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(val_labels, np.array(val_probs)>0.5, average='binary')\n",
    "    roc_auc = roc_auc_score(val_labels, val_probs)\n",
    "    \n",
    "    return precision, recall, f1, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "parental-aerospace",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "model = OutNet(notes_embeddings=128, events_embeddings=128)\n",
    "if torch.cuda.device_count() >0:\n",
    "    model.cuda()\n",
    "criterion = nn.BCELoss()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum = 0.9, nesterov = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "canadian-liabilities",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 0.001\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 0: curr_epoch_loss=0.8579788208007812\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 1: curr_epoch_loss=0.6818565726280212\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 2: curr_epoch_loss=0.43188226222991943\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 3: curr_epoch_loss=0.3713035583496094\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 4: curr_epoch_loss=0.3577061891555786\n",
      "Model Training time: 149.35582661628723\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "t0 = time.time()\n",
    "print('Learning Rate: ' + str(learning_rate))\n",
    "n_epochs = 10\n",
    "train(model, notes_orig_train_loader, notes_orig_val_loader, n_epochs)\n",
    "t1 = time.time()\n",
    "processing_time = t1-t0\n",
    "print('Model Training time: ' + str(processing_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "figured-dragon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =  0.616822429906542\nRecall    =  0.30697674418604654\nF1        =  0.40993788819875776\nROC AUC   =  0.8324651162790696\n"
     ]
    }
   ],
   "source": [
    "p, r, f, roc_auc = eval_model(model, notes_orig_val_loader)\n",
    "print(\"Precision = \",p)\n",
    "print(\"Recall    = \", r)\n",
    "print(\"F1        = \", f)\n",
    "print(\"ROC AUC   = \", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-computer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('ProgramData': virtualenv)",
   "name": "python385jvsc74a57bd0b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
