{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f",
   "display_name": "Python 3.8.5 64-bit ('ProgramData': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: nbformat in c:\\programdata\\anaconda3\\lib\\site-packages (5.0.8)\nRequirement already satisfied: ipython-genutils in c:\\programdata\\anaconda3\\lib\\site-packages (from nbformat) (0.2.0)\nRequirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbformat) (3.2.0)\nRequirement already satisfied: traitlets>=4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from nbformat) (5.0.5)\nRequirement already satisfied: jupyter-core in c:\\programdata\\anaconda3\\lib\\site-packages (from nbformat) (4.6.3)\nRequirement already satisfied: pyrsistent>=0.14.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat) (0.17.3)\nRequirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat) (50.3.1.post20201107)\nRequirement already satisfied: attrs>=17.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat) (20.3.0)\nRequirement already satisfied: six>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat) (1.15.0)\nRequirement already satisfied: pywin32>=1.0; sys_platform == \"win32\" in c:\\programdata\\anaconda3\\lib\\site-packages (from jupyter-core->nbformat) (227)\nUsing device: cuda\n\nNVIDIA GeForce GTX 1060 6GB\nMemory Usage:\nAllocated: 0.0 GB\nCached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "%run notes_events_network_join.ipynb"
   ]
  },
  {
   "source": [
    "# Hyperparameters experiment\n",
    "We train and eval the model varying the following:\n",
    "\n",
    "* cohorts: unbalanced vs balanced\n",
    "* optimizers: Adam vs SGD\n",
    "* learning rates\n",
    "* epochs\n",
    "* number of samples"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=0.4178662896156311\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 10: curr_epoch_loss=0.42086124420166016\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 11: curr_epoch_loss=0.418766587972641\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 12: curr_epoch_loss=0.4168277680873871\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 13: curr_epoch_loss=0.4196009039878845\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 14: curr_epoch_loss=0.41362619400024414\n",
      "Model Training time: 341.4437174797058\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Learning rate: 0.001\n",
      "Model Training time: 341.4437174797058\n",
      "Precision =  0.0\n",
      "Recall    =  0.0\n",
      "F1        =  0.0\n",
      "ROC AUC   =  0.6524737881358288\n",
      "0.0 \t 0.0 \t 0.0 \t 0.6524737881358288\n",
      "---------------\n",
      "\n",
      "\n",
      "Training for:\n",
      "\n",
      "Cohort        \t=  unbalanced\n",
      "Optimizer     \t=  SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.001\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Learning rate \t=  0.001\n",
      "No. of epochs \t=  15\n",
      "No. of samples\t=  0\n",
      "---------------\n",
      "Number of Patients: 9822\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 0: curr_epoch_loss=0.5986029505729675\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 1: curr_epoch_loss=0.45947468280792236\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 2: curr_epoch_loss=0.40913304686546326\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 3: curr_epoch_loss=0.3917708098888397\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 4: curr_epoch_loss=0.39335817098617554\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 5: curr_epoch_loss=0.3854242265224457\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 6: curr_epoch_loss=0.3883720934391022\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 7: curr_epoch_loss=0.38496798276901245\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 8: curr_epoch_loss=0.38553112745285034\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 9: curr_epoch_loss=0.3867499828338623\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 10: curr_epoch_loss=0.38427239656448364\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 11: curr_epoch_loss=0.3810783624649048\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 12: curr_epoch_loss=0.3806946277618408\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 13: curr_epoch_loss=0.38096919655799866\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 14: curr_epoch_loss=0.38135087490081787\n",
      "Model Training time: 604.8244655132294\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Learning rate: 0.001\n",
      "Model Training time: 604.8244655132294\n",
      "Precision =  0.0\n",
      "Recall    =  0.0\n",
      "F1        =  0.0\n",
      "ROC AUC   =  0.678708841762139\n",
      "0.0 \t 0.0 \t 0.0 \t 0.678708841762139\n",
      "---------------\n",
      "\n",
      "\n",
      "Training for:\n",
      "\n",
      "Cohort        \t=  unbalanced\n",
      "Optimizer     \t=  SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Learning rate \t=  0.01\n",
      "No. of epochs \t=  5\n",
      "No. of samples\t=  1000\n",
      "---------------\n",
      "Number of Patients: 9822\n",
      "***** Slicing to 1000\n",
      "Batch : 10, Epoch 0: curr_epoch_loss=0.6036660671234131\n",
      "Batch : 10, Epoch 1: curr_epoch_loss=0.4937397837638855\n",
      "Batch : 10, Epoch 2: curr_epoch_loss=0.4480133056640625\n",
      "Batch : 10, Epoch 3: curr_epoch_loss=0.4353371560573578\n",
      "Batch : 10, Epoch 4: curr_epoch_loss=0.42917293310165405\n",
      "Model Training time: 21.505822896957397\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Learning rate: 0.01\n",
      "Model Training time: 21.505822896957397\n",
      "Precision =  0.0\n",
      "Recall    =  0.0\n",
      "F1        =  0.0\n",
      "ROC AUC   =  0.6116268788682582\n",
      "0.0 \t 0.0 \t 0.0 \t 0.6116268788682582\n",
      "---------------\n",
      "\n",
      "\n",
      "Training for:\n",
      "\n",
      "Cohort        \t=  unbalanced\n",
      "Optimizer     \t=  SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Learning rate \t=  0.01\n",
      "No. of epochs \t=  5\n",
      "No. of samples\t=  5000\n",
      "---------------\n",
      "Number of Patients: 9822\n",
      "***** Slicing to 5000\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 0: curr_epoch_loss=0.46975135803222656\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 1: curr_epoch_loss=0.4069051742553711\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 2: curr_epoch_loss=0.4064590334892273\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 3: curr_epoch_loss=0.39720338582992554\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 4: curr_epoch_loss=0.39028027653694153\n",
      "Model Training time: 114.71204471588135\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Learning rate: 0.01\n",
      "Model Training time: 114.71204471588135\n",
      "Precision =  0.0\n",
      "Recall    =  0.0\n",
      "F1        =  0.0\n",
      "ROC AUC   =  0.6787770156147669\n",
      "0.0 \t 0.0 \t 0.0 \t 0.6787770156147669\n",
      "---------------\n",
      "\n",
      "\n",
      "Training for:\n",
      "\n",
      "Cohort        \t=  unbalanced\n",
      "Optimizer     \t=  SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Learning rate \t=  0.01\n",
      "No. of epochs \t=  5\n",
      "No. of samples\t=  0\n",
      "---------------\n",
      "Number of Patients: 9822\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 0: curr_epoch_loss=0.40969282388687134\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 1: curr_epoch_loss=0.38053104281425476\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 2: curr_epoch_loss=0.37216514348983765\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 3: curr_epoch_loss=0.3659478724002838\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 4: curr_epoch_loss=0.359284907579422\n",
      "Model Training time: 199.48863697052002\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Learning rate: 0.01\n",
      "Model Training time: 199.48863697052002\n",
      "Precision =  0.0\n",
      "Recall    =  0.0\n",
      "F1        =  0.0\n",
      "ROC AUC   =  0.7229207454471573\n",
      "0.0 \t 0.0 \t 0.0 \t 0.7229207454471573\n",
      "---------------\n",
      "\n",
      "\n",
      "Training for:\n",
      "\n",
      "Cohort        \t=  unbalanced\n",
      "Optimizer     \t=  SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Learning rate \t=  0.01\n",
      "No. of epochs \t=  10\n",
      "No. of samples\t=  1000\n",
      "---------------\n",
      "Number of Patients: 9822\n",
      "***** Slicing to 1000\n",
      "Batch : 10, Epoch 0: curr_epoch_loss=0.6258370280265808\n",
      "Batch : 10, Epoch 1: curr_epoch_loss=0.5116122364997864\n",
      "Batch : 10, Epoch 2: curr_epoch_loss=0.46681809425354004\n",
      "Batch : 10, Epoch 3: curr_epoch_loss=0.45291540026664734\n",
      "Batch : 10, Epoch 4: curr_epoch_loss=0.44060903787612915\n",
      "Batch : 10, Epoch 5: curr_epoch_loss=0.4405343532562256\n",
      "Batch : 10, Epoch 6: curr_epoch_loss=0.4345373213291168\n",
      "Batch : 10, Epoch 7: curr_epoch_loss=0.43456941843032837\n",
      "Batch : 10, Epoch 8: curr_epoch_loss=0.43270963430404663\n",
      "Batch : 10, Epoch 9: curr_epoch_loss=0.42242586612701416\n",
      "Model Training time: 43.637895822525024\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Learning rate: 0.01\n",
      "Model Training time: 43.637895822525024\n",
      "Precision =  0.0\n",
      "Recall    =  0.0\n",
      "F1        =  0.0\n",
      "ROC AUC   =  0.5505555555555557\n",
      "0.0 \t 0.0 \t 0.0 \t 0.5505555555555557\n",
      "---------------\n",
      "\n",
      "\n",
      "Training for:\n",
      "\n",
      "Cohort        \t=  unbalanced\n",
      "Optimizer     \t=  SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Learning rate \t=  0.01\n",
      "No. of epochs \t=  10\n",
      "No. of samples\t=  5000\n",
      "---------------\n",
      "Number of Patients: 9822\n",
      "***** Slicing to 5000\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 0: curr_epoch_loss=0.4577285349369049\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 1: curr_epoch_loss=0.4119580388069153\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 2: curr_epoch_loss=0.4071670472621918\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 3: curr_epoch_loss=0.3957836627960205\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 4: curr_epoch_loss=0.38907936215400696\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 5: curr_epoch_loss=0.38463106751441956\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 6: curr_epoch_loss=0.3781980276107788\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 7: curr_epoch_loss=0.37140196561813354\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 8: curr_epoch_loss=0.36320796608924866\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 9: curr_epoch_loss=0.35188883543014526\n",
      "Model Training time: 224.79536151885986\n",
      "Learning rate: 0.01\n",
      "Model Training time: 224.79536151885986\n",
      "Precision =  0.42857142857142855\n",
      "Recall    =  0.046153846153846156\n",
      "F1        =  0.08333333333333333\n",
      "ROC AUC   =  0.7473032714412026\n",
      "0.42857142857142855 \t 0.046153846153846156 \t 0.08333333333333333 \t 0.7473032714412026\n",
      "---------------\n",
      "\n",
      "\n",
      "Training for:\n",
      "\n",
      "Cohort        \t=  unbalanced\n",
      "Optimizer     \t=  SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Learning rate \t=  0.01\n",
      "No. of epochs \t=  10\n",
      "No. of samples\t=  0\n",
      "---------------\n",
      "Number of Patients: 9822\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 0: curr_epoch_loss=0.42880576848983765\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 1: curr_epoch_loss=0.38330188393592834\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 2: curr_epoch_loss=0.37545841932296753\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 3: curr_epoch_loss=0.3689303696155548\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 4: curr_epoch_loss=0.3614037334918976\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 5: curr_epoch_loss=0.3555945158004761\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 6: curr_epoch_loss=0.3499026596546173\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 7: curr_epoch_loss=0.33203521370887756\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 8: curr_epoch_loss=0.31453752517700195\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 9: curr_epoch_loss=0.30091217160224915\n",
      "Model Training time: 395.63303542137146\n",
      "Learning rate: 0.01\n",
      "Model Training time: 395.63303542137146\n",
      "Precision =  0.46153846153846156\n",
      "Recall    =  0.225\n",
      "F1        =  0.3025210084033614\n",
      "ROC AUC   =  0.7843405797101448\n",
      "0.46153846153846156 \t 0.225 \t 0.3025210084033614 \t 0.7843405797101448\n",
      "---------------\n",
      "\n",
      "\n",
      "Training for:\n",
      "\n",
      "Cohort        \t=  unbalanced\n",
      "Optimizer     \t=  SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Learning rate \t=  0.01\n",
      "No. of epochs \t=  15\n",
      "No. of samples\t=  1000\n",
      "---------------\n",
      "Number of Patients: 9822\n",
      "***** Slicing to 1000\n",
      "Batch : 10, Epoch 0: curr_epoch_loss=0.5796506404876709\n",
      "Batch : 10, Epoch 1: curr_epoch_loss=0.48540353775024414\n",
      "Batch : 10, Epoch 2: curr_epoch_loss=0.44727200269699097\n",
      "Batch : 10, Epoch 3: curr_epoch_loss=0.4295482635498047\n",
      "Batch : 10, Epoch 4: curr_epoch_loss=0.41945013403892517\n",
      "Batch : 10, Epoch 5: curr_epoch_loss=0.42105862498283386\n",
      "Batch : 10, Epoch 6: curr_epoch_loss=0.42494046688079834\n",
      "Batch : 10, Epoch 7: curr_epoch_loss=0.42234817147254944\n",
      "Batch : 10, Epoch 8: curr_epoch_loss=0.41801345348358154\n",
      "Batch : 10, Epoch 9: curr_epoch_loss=0.42154425382614136\n",
      "Batch : 10, Epoch 10: curr_epoch_loss=0.41907253861427307\n",
      "Batch : 10, Epoch 11: curr_epoch_loss=0.4095381796360016\n",
      "Batch : 10, Epoch 12: curr_epoch_loss=0.42100635170936584\n",
      "Batch : 10, Epoch 13: curr_epoch_loss=0.41000837087631226\n",
      "Batch : 10, Epoch 14: curr_epoch_loss=0.4144173264503479\n",
      "Model Training time: 61.31273031234741\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Learning rate: 0.01\n",
      "Model Training time: 61.31273031234741\n",
      "Precision =  0.0\n",
      "Recall    =  0.0\n",
      "F1        =  0.0\n",
      "ROC AUC   =  0.5287356321839081\n",
      "0.0 \t 0.0 \t 0.0 \t 0.5287356321839081\n",
      "---------------\n",
      "\n",
      "\n",
      "Training for:\n",
      "\n",
      "Cohort        \t=  unbalanced\n",
      "Optimizer     \t=  SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Learning rate \t=  0.01\n",
      "No. of epochs \t=  15\n",
      "No. of samples\t=  5000\n",
      "---------------\n",
      "Number of Patients: 9822\n",
      "***** Slicing to 5000\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 0: curr_epoch_loss=0.4543423056602478\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 1: curr_epoch_loss=0.4083881378173828\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 2: curr_epoch_loss=0.4079335331916809\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 3: curr_epoch_loss=0.4039122462272644\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 4: curr_epoch_loss=0.39629679918289185\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 5: curr_epoch_loss=0.39283615350723267\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 6: curr_epoch_loss=0.39052438735961914\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 7: curr_epoch_loss=0.3833635449409485\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 8: curr_epoch_loss=0.3753172755241394\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 9: curr_epoch_loss=0.36593014001846313\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 10: curr_epoch_loss=0.35943859815597534\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 11: curr_epoch_loss=0.34120097756385803\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 12: curr_epoch_loss=0.32967814803123474\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 13: curr_epoch_loss=0.3140869736671448\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, Epoch 14: curr_epoch_loss=0.29854616522789\n",
      "Model Training time: 325.31057810783386\n",
      "Learning rate: 0.01\n",
      "Model Training time: 325.31057810783386\n",
      "Precision =  0.4909090909090909\n",
      "Recall    =  0.1888111888111888\n",
      "F1        =  0.2727272727272727\n",
      "ROC AUC   =  0.7951057110917088\n",
      "0.4909090909090909 \t 0.1888111888111888 \t 0.2727272727272727 \t 0.7951057110917088\n",
      "---------------\n",
      "\n",
      "\n",
      "Training for:\n",
      "\n",
      "Cohort        \t=  unbalanced\n",
      "Optimizer     \t=  SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Learning rate \t=  0.01\n",
      "No. of epochs \t=  15\n",
      "No. of samples\t=  0\n",
      "---------------\n",
      "Number of Patients: 9822\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 0: curr_epoch_loss=0.41705322265625\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 1: curr_epoch_loss=0.38083961606025696\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 2: curr_epoch_loss=0.3754115402698517\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 3: curr_epoch_loss=0.36943644285202026\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 4: curr_epoch_loss=0.36018380522727966\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 5: curr_epoch_loss=0.35271957516670227\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 6: curr_epoch_loss=0.3478204309940338\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 7: curr_epoch_loss=0.3291776776313782\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 8: curr_epoch_loss=0.31279635429382324\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 9: curr_epoch_loss=0.29512473940849304\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 10: curr_epoch_loss=0.27892032265663147\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 11: curr_epoch_loss=0.2651282250881195\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 12: curr_epoch_loss=0.2524230182170868\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 13: curr_epoch_loss=0.24421803653240204\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, Epoch 14: curr_epoch_loss=0.2339780032634735\n",
      "Model Training time: 567.3957092761993\n",
      "Learning rate: 0.01\n",
      "Model Training time: 567.3957092761993\n",
      "Precision =  0.5299539170506913\n",
      "Recall    =  0.4713114754098361\n",
      "F1        =  0.4989154013015185\n",
      "ROC AUC   =  0.8363060934835828\n",
      "0.5299539170506913 \t 0.4713114754098361 \t 0.4989154013015185 \t 0.8363060934835828\n",
      "---------------\n",
      "\n",
      "\n",
      "Training for:\n",
      "\n",
      "Cohort        \t=  balanced\n",
      "Optimizer     \t=  Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0\n",
      ")\n",
      "Learning rate \t=  0.0001\n",
      "No. of epochs \t=  5\n",
      "No. of samples\t=  1000\n",
      "---------------\n",
      "* Train dataset *\n",
      "Number of Patients: 13790\n",
      "* Test dataset *\n",
      "Number of Patients: 1965\n",
      "***** Slicing to 1000\n",
      "Batch : 10, Epoch 0: curr_epoch_loss=0.45979076623916626\n",
      "Batch : 10, Epoch 1: curr_epoch_loss=0.1938546746969223\n",
      "Batch : 10, Epoch 2: curr_epoch_loss=0.06779135763645172\n",
      "Batch : 10, Epoch 3: curr_epoch_loss=0.028438806533813477\n",
      "Batch : 10, Epoch 4: curr_epoch_loss=0.016201380640268326\n",
      "Model Training time: 22.355223178863525\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Learning rate: 0.0001\n",
      "Model Training time: 22.355223178863525\n",
      "Precision =  0.0\n",
      "Recall    =  0.0\n",
      "F1        =  0.0\n",
      "ROC AUC   =  0.42471229978059327\n",
      "0.0 \t 0.0 \t 0.0 \t 0.42471229978059327\n",
      "---------------\n",
      "\n",
      "\n",
      "Training for:\n",
      "\n",
      "Cohort        \t=  balanced\n",
      "Optimizer     \t=  Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0\n",
      ")\n",
      "Learning rate \t=  0.0001\n",
      "No. of epochs \t=  5\n",
      "No. of samples\t=  5000\n",
      "---------------\n",
      "* Train dataset *\n",
      "Number of Patients: 13790\n",
      "* Test dataset *\n",
      "Number of Patients: 1965\n",
      "***** Slicing to 5000\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, Epoch 0: curr_epoch_loss=0.1391712874174118\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, Epoch 1: curr_epoch_loss=0.004775721114128828\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, Epoch 2: curr_epoch_loss=0.001533147064037621\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, Epoch 3: curr_epoch_loss=0.0009012730442918837\n",
      "Batch : 10, 20, 30, 40, 50, 60, 70, 80, 90, Epoch 4: curr_epoch_loss=0.0005388266872614622\n",
      "Model Training time: 110.49102449417114\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 1965 is out of bounds for axis 0 with size 1965",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-28ab60633f92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                     \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_unbalanced_dataloaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcohort\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'unbalanced'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mget_balanced_dataloaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                     \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_and_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m                     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'---------------\\n\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-cb0bb468b0bb>\u001b[0m in \u001b[0;36mtrain_and_eval\u001b[1;34m(model, train_loader, val_loader, n_epochs, filename)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model Training time: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessing_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Learning rate: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Model Training time: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessing_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-317d28163731>\u001b[0m in \u001b[0;36meval_model\u001b[1;34m(model, val_loader)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mval_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevents_masks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-f28406a47ebf>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mevents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_code\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcodes\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1965 is out of bounds for axis 0 with size 1965"
     ]
    }
   ],
   "source": [
    "cohorts = ['unbalanced', 'balanced']\n",
    "optimizers = [torch.optim.Adam, torch.optim.SGD]\n",
    "learning_rates = [0.0001, 0.001, 0.01]\n",
    "epochs = [5, 10, 15]\n",
    "samples = [1000, 5000, 0]\n",
    "\n",
    "results = np.empty(shape=(len(cohorts), len(optimizers), len(learning_rates), len(epochs), len(samples)), dtype='object')\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "for c, cohort in enumerate(cohorts):\n",
    "    for o, optim in enumerate(optimizers):\n",
    "        for l, learning_rate in enumerate(learning_rates):\n",
    "            for e, n_epochs in enumerate(epochs):\n",
    "                for s, n_samples in enumerate(samples):\n",
    "                    model, optimizer = create_model_and_optimizer()\n",
    "                    optimizer = optim(model.parameters(), lr=learning_rate)\n",
    "                    print (\"Training for:\\n\")\n",
    "                    print (\"Cohort        \\t= \", cohort)\n",
    "                    print (\"Optimizer     \\t= \", optimizer)\n",
    "                    print (\"Learning rate \\t= \", learning_rate)\n",
    "                    print (\"No. of epochs \\t= \", n_epochs)\n",
    "                    print (\"No. of samples\\t= \", n_samples)\n",
    "                    print ('---------------')\n",
    "                    model_filename = cohort + '-' + str(o) + '-' + str(learning_rate) + '-' + str(n_epochs) + '-' + str(n_samples) + '.pt'\n",
    "\n",
    "                    train_loader, val_loader = get_unbalanced_dataloaders(n_samples) if cohort=='unbalanced' else get_balanced_dataloaders(n_samples)                    \n",
    "                    p, r, f, roc_auc = train_and_eval(model, train_loader, val_loader, n_epochs, model_filename)\n",
    "                    results[c,o,l,e,s] = [p, r, f, roc_auc]\n",
    "                    print ('---------------\\n\\n')\n"
   ]
  },
  {
   "source": [
    "## Saving of the results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "r = {}\n",
    "r['cohorts'] = cohorts\n",
    "r['optimizers'] = optimizers\n",
    "r['learning_rates'] = learning_rates\n",
    "r['epochs'] = epochs\n",
    "r['samples'] = samples\n",
    "r['results'] = results\n",
    "pickle.dump( r, open(\"hyperparam-exp-\" + now.strftime(\"%Y%m%d-%H%M\") +\".p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}